env:
  - cd /home/zbr/Workspace/proj/uspp2pm
  - conda activate uspp
name: run_uspp
cmd:
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 10 --lr 0.00002 --wd 1 --nproc_per_node 1
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 10 --lr 0.00002 --wd 0.1 --nproc_per_node 1
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 10 --lr 0.00002 --wd 0.01 --nproc_per_node 1
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 10 --lr 0.00002 --wd 0.001 --nproc_per_node 1
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 10 --lr 0.00002 --wd 0.0001 --nproc_per_node 1
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 20 --lr 0.000001 --wd 0.01 --nproc_per_node 1
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 20 --lr 0.000002 --wd 0.01 --nproc_per_node 1
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 20 --lr 0.00002 --wd 0.01 --nproc_per_node 1
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 20 --lr 0.0002 --wd 0.01 --nproc_per_node 1
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 20 --lr 0.002 --wd 0.01 --nproc_per_node 1
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 20 --lr 0.005 --wd 0.01 --nproc_per_node 1
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 20 --lr 0.000001 --wd 1 --nproc_per_node 1
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 20 --lr 0.000002 --wd 1 --nproc_per_node 1
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 20 --lr 0.00002 --wd 1 --nproc_per_node 1
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 20 --lr 0.0002 --wd 1 --nproc_per_node 1
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 20 --lr 0.002 --wd 1 --nproc_per_node 1
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 20 --lr 0.005 --wd 1 --nproc_per_node 1
  # 2022-05-28
  # - python train.py --num_fold 5 --dataset_name split --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 10 --lr 0.00002 --wd 0.01 --nproc_per_node 1
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name pearson --bs 48 --epochs 10 --lr 0.00002 --wd 0.01 --nproc_per_node 1
  # 2022-05-29
  # - python train.py --num_fold 5 --dataset_name split --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 10 --lr 0.00002 --wd 0.01 --nproc_per_node 1 --lr_multi 1
  # - python train.py --num_fold 5 --dataset_name split --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 10 --lr 0.00002 --wd 0.01 --nproc_per_node 1 --lr_multi 10 --model_name split_baseline
  # - python train.py --num_fold 5 --dataset_name split --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 10 --lr 0.00002 --wd 0.01 --nproc_per_node 1 --lr_multi 100 --model_name split_baseline
  # - python train.py --num_fold 5 --dataset_name split --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 10 --lr 0.00002 --wd 0.01 --nproc_per_node 1 --lr_multi 10 --num_layer 2 --model_name split_baseline
  # - python train.py --num_fold 5 --dataset_name split --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 10 --lr 0.00002 --wd 0.01 --nproc_per_node 1 --lr_multi 10 --num_layer 3 --model_name split_baseline
  # - python train.py --num_fold 5 --dataset_name split --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 10 --lr 0.00002 --wd 0.01 --nproc_per_node 1 --lr_multi 10 --num_layer 1 --model_name split_similarity
  # 2022-05-30
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 15 --lr 0.00002 --wd 0.01 --nproc_per_node 1 --lr_multi 1 --num_layer 1 --model_name combined_baseline
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 15 --lr 0.00002 --wd 0.01 --nproc_per_node 1 --lr_multi 1 --num_layer 2 --model_name combined_baseline
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 15 --lr 0.00002 --wd 0.01 --nproc_per_node 1 --lr_multi 10 --num_layer 2 --model_name combined_baseline
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 15 --lr 0.00002 --wd 0.01 --nproc_per_node 1 --lr_multi 1 --num_layer 3 --model_name combined_baseline
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name match --bs 48 --epochs 15 --lr 0.00002 --wd 0.01 --nproc_per_node 1 --lr_multi 1 --num_layer 1 --model_name combined_baseline