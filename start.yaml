env:
  - cd /home/zbr/Workspace/proj/uspp2pm
  - conda activate uspp
name: run_uspp
cmd:
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 10 --lr 0.00002 --wd 1 --nproc_per_node 1
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 10 --lr 0.00002 --wd 0.1 --nproc_per_node 1
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 10 --lr 0.00002 --wd 0.01 --nproc_per_node 1
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 10 --lr 0.00002 --wd 0.001 --nproc_per_node 1
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 10 --lr 0.00002 --wd 0.0001 --nproc_per_node 1
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 20 --lr 0.000001 --wd 0.01 --nproc_per_node 1
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 20 --lr 0.000002 --wd 0.01 --nproc_per_node 1
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 20 --lr 0.00002 --wd 0.01 --nproc_per_node 1
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 20 --lr 0.0002 --wd 0.01 --nproc_per_node 1
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 20 --lr 0.002 --wd 0.01 --nproc_per_node 1
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 20 --lr 0.005 --wd 0.01 --nproc_per_node 1
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 20 --lr 0.000001 --wd 1 --nproc_per_node 1
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 20 --lr 0.000002 --wd 1 --nproc_per_node 1
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 20 --lr 0.00002 --wd 1 --nproc_per_node 1
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 20 --lr 0.0002 --wd 1 --nproc_per_node 1
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 20 --lr 0.002 --wd 1 --nproc_per_node 1
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 20 --lr 0.005 --wd 1 --nproc_per_node 1
  # 2022-05-28
  # - python train.py --num_fold 5 --dataset_name split --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 10 --lr 0.00002 --wd 0.01 --nproc_per_node 1
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name pearson --bs 48 --epochs 10 --lr 0.00002 --wd 0.01 --nproc_per_node 1
  # 2022-05-29
  # - python train.py --num_fold 5 --dataset_name split --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 10 --lr 0.00002 --wd 0.01 --nproc_per_node 1 --lr_multi 1
  # - python train.py --num_fold 5 --dataset_name split --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 10 --lr 0.00002 --wd 0.01 --nproc_per_node 1 --lr_multi 10 --model_name split_baseline
  # - python train.py --num_fold 5 --dataset_name split --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 10 --lr 0.00002 --wd 0.01 --nproc_per_node 1 --lr_multi 100 --model_name split_baseline
  # - python train.py --num_fold 5 --dataset_name split --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 10 --lr 0.00002 --wd 0.01 --nproc_per_node 1 --lr_multi 10 --num_layer 2 --model_name split_baseline
  # - python train.py --num_fold 5 --dataset_name split --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 10 --lr 0.00002 --wd 0.01 --nproc_per_node 1 --lr_multi 10 --num_layer 3 --model_name split_baseline
  # - python train.py --num_fold 5 --dataset_name split --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 10 --lr 0.00002 --wd 0.01 --nproc_per_node 1 --lr_multi 10 --num_layer 1 --model_name split_similarity
  # 2022-05-30
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 15 --lr 0.00002 --wd 0.01 --nproc_per_node 1 --lr_multi 1 --num_layer 1 --model_name combined_baseline
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 15 --lr 0.00002 --wd 0.01 --nproc_per_node 1 --lr_multi 1 --num_layer 2 --model_name combined_baseline
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 15 --lr 0.00002 --wd 0.01 --nproc_per_node 1 --lr_multi 10 --num_layer 2 --model_name combined_baseline
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 15 --lr 0.00002 --wd 0.01 --nproc_per_node 1 --lr_multi 1 --num_layer 3 --model_name combined_baseline
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name match --bs 48 --epochs 15 --lr 0.00002 --wd 0.01 --nproc_per_node 1 --lr_multi 1 --num_layer 1 --model_name combined_baseline
  # - python train.py --bs 48 --dataset_name combined --epochs 15 --loss_name mse --lr 2e-05 --lr_multi 1 --model_name combined_hdc --nproc_per_node 1 --num_block 2 --num_fold 5 --num_layer 1 --pretrain_name deberta-v3-base --scale 1.0 --update_rate 0.01 --wd 0.01
  # - python train.py --bs 48 --dataset_name combined --epochs 15 --loss_name mse --lr 2e-05 --lr_multi 1 --model_name combined_hdc --nproc_per_node 1 --num_block 2 --num_fold 5 --num_layer 1 --pretrain_name deberta-v3-base --scale 1.0 --update_rate 0.05 --wd 0.01
  # - python train.py --bs 48 --dataset_name combined --epochs 15 --loss_name mse --lr 2e-05 --lr_multi 10 --model_name combined_hdc --nproc_per_node 1 --num_block 2 --num_fold 5 --num_layer 1 --pretrain_name deberta-v3-base --scale 1.0 --update_rate 0.01 --wd 0.01
  # - python train.py --bs 48 --dataset_name combined --epochs 15 --loss_name mse --lr 2e-05 --lr_multi 10 --model_name combined_hdc --nproc_per_node 1 --num_block 2 --num_fold 5 --num_layer 1 --pretrain_name deberta-v3-base --scale 1.0 --update_rate 0.05 --wd 0.01
  # - python train.py --bs 48 --dataset_name combined --epochs 15 --loss_name mse --lr 2e-05 --lr_multi 1 --model_name combined_hdc --nproc_per_node 1 --num_block 3 --num_fold 5 --num_layer 1 --pretrain_name deberta-v3-base --scale 1.0 --update_rate 0.01 --wd 0.01
  # - python train.py --bs 48 --dataset_name combined --epochs 15 --loss_name mse --lr 2e-05 --lr_multi 1 --model_name combined_hdc --nproc_per_node 1 --num_block 3 --num_fold 5 --num_layer 1 --pretrain_name deberta-v3-base --scale 1.0 --update_rate 0.05 --wd 0.01
  # - python train.py --bs 48 --dataset_name combined --epochs 15 --loss_name mse --lr 2e-05 --lr_multi 10 --model_name combined_hdc --nproc_per_node 1 --num_block 3 --num_fold 5 --num_layer 1 --pretrain_name deberta-v3-base --scale 1.0 --update_rate 0.01 --wd 0.01
  # - python train.py --bs 48 --dataset_name combined --epochs 15 --loss_name mse --lr 2e-05 --lr_multi 10 --model_name combined_hdc --nproc_per_node 1 --num_block 3 --num_fold 5 --num_layer 1 --pretrain_name deberta-v3-base --scale 1.0 --update_rate 0.05 --wd 0.01
  # - python train.py --bs 48 --dataset_name combined --epochs 15 --loss_name mse --lr 2e-05 --lr_multi 1 --model_name combined_hdc --nproc_per_node 1 --num_block 4 --num_fold 5 --num_layer 1 --pretrain_name deberta-v3-base --scale 1.0 --update_rate 0.01 --wd 0.01
  # - python train.py --bs 48 --dataset_name combined --epochs 15 --loss_name mse --lr 2e-05 --lr_multi 1 --model_name combined_hdc --nproc_per_node 1 --num_block 4 --num_fold 5 --num_layer 1 --pretrain_name deberta-v3-base --scale 1.0 --update_rate 0.05 --wd 0.01
  # - python train.py --bs 48 --dataset_name combined --epochs 15 --loss_name mse --lr 2e-05 --lr_multi 10 --model_name combined_hdc --nproc_per_node 1 --num_block 4 --num_fold 5 --num_layer 1 --pretrain_name deberta-v3-base --scale 1.0 --update_rate 0.01 --wd 0.01
  # - python train.py --bs 48 --dataset_name combined --epochs 15 --loss_name mse --lr 2e-05 --lr_multi 10 --model_name combined_hdc --nproc_per_node 1 --num_block 4 --num_fold 5 --num_layer 1 --pretrain_name deberta-v3-base --scale 1.0 --update_rate 0.05 --wd 0.01
  # - python train.py --bs 48 --dataset_name combined --epochs 15 --loss_name mse --lr 2e-05 --lr_multi 1 --model_name combined_hdc --nproc_per_node 1 --num_block 2 --num_fold 5 --num_layer 2 --pretrain_name deberta-v3-base --scale 1.0 --update_rate 0.01 --wd 0.01
  # - python train.py --bs 48 --dataset_name combined --epochs 15 --loss_name mse --lr 2e-05 --lr_multi 1 --model_name combined_hdc --nproc_per_node 1 --num_block 2 --num_fold 5 --num_layer 2 --pretrain_name deberta-v3-base --scale 1.0 --update_rate 0.05 --wd 0.01
  # - python train.py --bs 48 --dataset_name combined --epochs 15 --loss_name mse --lr 2e-05 --lr_multi 10 --model_name combined_hdc --nproc_per_node 1 --num_block 2 --num_fold 5 --num_layer 2 --pretrain_name deberta-v3-base --scale 1.0 --update_rate 0.01 --wd 0.01
  # - python train.py --bs 48 --dataset_name combined --epochs 15 --loss_name mse --lr 2e-05 --lr_multi 10 --model_name combined_hdc --nproc_per_node 1 --num_block 2 --num_fold 5 --num_layer 2 --pretrain_name deberta-v3-base --scale 1.0 --update_rate 0.05 --wd 0.01
  # - python train.py --bs 48 --dataset_name combined --epochs 15 --loss_name mse --lr 2e-05 --lr_multi 1 --model_name combined_hdc --nproc_per_node 1 --num_block 3 --num_fold 5 --num_layer 2 --pretrain_name deberta-v3-base --scale 1.0 --update_rate 0.01 --wd 0.01
  # - python train.py --bs 48 --dataset_name combined --epochs 15 --loss_name mse --lr 2e-05 --lr_multi 1 --model_name combined_hdc --nproc_per_node 1 --num_block 3 --num_fold 5 --num_layer 2 --pretrain_name deberta-v3-base --scale 1.0 --update_rate 0.05 --wd 0.01
  # - python train.py --bs 48 --dataset_name combined --epochs 15 --loss_name mse --lr 2e-05 --lr_multi 10 --model_name combined_hdc --nproc_per_node 1 --num_block 3 --num_fold 5 --num_layer 2 --pretrain_name deberta-v3-base --scale 1.0 --update_rate 0.01 --wd 0.01
  # - python train.py --bs 48 --dataset_name combined --epochs 15 --loss_name mse --lr 2e-05 --lr_multi 10 --model_name combined_hdc --nproc_per_node 1 --num_block 3 --num_fold 5 --num_layer 2 --pretrain_name deberta-v3-base --scale 1.0 --update_rate 0.05 --wd 0.01
  # - python train.py --bs 48 --dataset_name combined --epochs 15 --loss_name mse --lr 2e-05 --lr_multi 1 --model_name combined_hdc --nproc_per_node 1 --num_block 4 --num_fold 5 --num_layer 2 --pretrain_name deberta-v3-base --scale 1.0 --update_rate 0.01 --wd 0.01
  # - python train.py --bs 48 --dataset_name combined --epochs 15 --loss_name mse --lr 2e-05 --lr_multi 1 --model_name combined_hdc --nproc_per_node 1 --num_block 4 --num_fold 5 --num_layer 2 --pretrain_name deberta-v3-base --scale 1.0 --update_rate 0.05 --wd 0.01
  # - python train.py --bs 48 --dataset_name combined --epochs 15 --loss_name mse --lr 2e-05 --lr_multi 10 --model_name combined_hdc --nproc_per_node 1 --num_block 4 --num_fold 5 --num_layer 2 --pretrain_name deberta-v3-base --scale 1.0 --update_rate 0.01 --wd 0.01
  # - python train.py --bs 48 --dataset_name combined --epochs 15 --loss_name mse --lr 2e-05 --lr_multi 10 --model_name combined_hdc --nproc_per_node 1 --num_block 4 --num_fold 5 --num_layer 2 --pretrain_name deberta-v3-base --scale 1.0 --update_rate 0.05 --wd 0.01
  # 2022-06-01
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 10 --nproc_per_node 1 --model_name combined_baseline --num_layer 2 --num_block 4 --update_rate 0.01 --dropout 0.5 --growth_rate 2 --lr_multi 10 --scale 4.0 --output_dim 768 --handler_name cls_emb
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 10 --nproc_per_node 1 --model_name combined_baseline --num_layer 2 --num_block 4 --update_rate 0.01 --dropout 0.5 --growth_rate 2 --lr_multi 10 --scale 4.0 --output_dim 768 --handler_name hidden_cls_emb
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 10 --nproc_per_node 1 --model_name combined_baseline --num_layer 2 --num_block 4 --update_rate 0.01 --dropout 0.5 --growth_rate 2 --lr_multi 10 --scale 4.0 --output_dim 768 --handler_name max_pooling
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 10 --nproc_per_node 1 --model_name combined_baseline --num_layer 2 --num_block 4 --update_rate 0.01 --dropout 0.5 --growth_rate 2 --lr_multi 10 --scale 4.0 --output_dim 768 --handler_name mean_max_pooling
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 10 --nproc_per_node 1 --model_name combined_baseline --num_layer 2 --num_block 4 --update_rate 0.01 --dropout 0.5 --growth_rate 2 --lr_multi 10 --scale 4.0 --output_dim 768 --handler_name hidden_cls_emb
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 10 --nproc_per_node 1 --model_name combined_baseline --num_layer 2 --num_block 4 --update_rate 0.01 --dropout 0.5 --growth_rate 2 --lr_multi 10 --scale 4.0 --output_dim 768 --handler_name hidden_weighted_cls_emb
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 10 --nproc_per_node 1 --model_name combined_baseline --num_layer 2 --num_block 4 --update_rate 0.01 --dropout 0.5 --growth_rate 2 --lr_multi 10 --scale 4.0 --output_dim 768 --handler_name hidden_lstm_cls_emb
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 10 --nproc_per_node 1 --model_name combined_baseline --num_layer 2 --num_block 4 --update_rate 0.01 --dropout 0.5 --growth_rate 2 --lr_multi 10 --scale 4.0 --output_dim 768 --handler_name hidden_attention_cls_emb
  # 2022-06-02
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 10 --nproc_per_node 1 --model_name combined_baseline --num_layer 2 --num_block 4 --update_rate 0.01 --dropout 0.5 --growth_rate 2 --lr_multi 10 --scale 4.0 --output_dim 768 --handler_name hidden_2_mean_max_pooling
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-base --loss_name mse --bs 48 --epochs 10 --nproc_per_node 1 --model_name combined_baseline --num_layer 2 --num_block 4 --update_rate 0.01 --dropout 0.5 --growth_rate 2 --lr_multi 10 --scale 4.0 --output_dim 768 --handler_name hidden_2_cls_mean_max_pooling
  # 2022-06-03
  # - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-large --loss_name mse --bs 24 --epochs 10 --nproc_per_node 2 --model_name combined_hdc --num_layer 2 --num_block 4 --update_rate 0.01 --dropout 0.5 --growth_rate 2 --lr_multi 10 --scale 4.0 --output_dim 1024 --handler_name hidden_2_mean_max_pooling
  - python train.py --num_fold 5 --dataset_name combined --pretrain_name deberta-v3-large --loss_name mse --bs 24 --epochs 10 --nproc_per_node 2 --model_name combined_hdc_v2 --num_layer 2 --num_block 4 --update_rate 0.01 --dropout 0.5 --growth_rate 2 --lr_multi 10 --scale 4.0 --output_dim 1024 --handler_name hidden_branch_mean_max_pooling --ensemble_name default